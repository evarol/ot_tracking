{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration of video frames using optimal transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Problem and general approach\n",
    "\n",
    "The practical problem we are ultimately trying to solve here is learning to 'straighten' videos of freely-behaving *C. elegans* specimens -- more precisely, to map the different frames of a given video into a canonical space where the spatial footprints of the worm's neurons remain static across frames. One way to accomplish this is to learn a spatial transformation between each pair of successive frames that captures the worm's motion, and compose these transformations in order to map all frames to a shared space.\n",
    "\n",
    "Image registration -- the problem of learning the spatial transformation between two images -- has been studied extensively in the computer vision literature. In its most general case, it can be stated as follows. Given two images $A$ and $B$ that are related by a spatial transform $T$ with a known parameteric form and set of parameters $\\theta$, we want to estimate $\\theta$. Without any other assumptions, this case of the problem is extremely difficult to solve. However, for our purposes working with microscopy images, there are a number of additional assumptions we can make. One is that all of the images we work with consist of small regions of high pixel intensity on top of a black background. This means we can expect all regions of high pixel intensity to be affected by $T$. Another is that, because $A$ and $B$ are successive frames in a microscopy video with a reasonably high sample rate, the displacement of objects between $A$ and $B$ should be small, and the correspondence between objects in $A$ and $B$ should be unambiguous.\n",
    "\n",
    "Given these assumptions, we believe we can use an optimal transport (OT) plan to approximate the motion of the objects between images $A$ and $B$. By assuming a parametric form for the transport plan we expect to result from a particular transform $T$ (in terms of its parameters $\\theta$), we can find the value of $\\theta$ that minimizes the difference between this transport plan and the true optimal transport plan. \n",
    "\n",
    "### Derivation\n",
    "\n",
    "#### Notation\n",
    "\n",
    "- $A, B$: Images related by $T_{\\theta}$\n",
    "- $T_{\\theta}$: Spatial transform with list of parameters $\\theta$, that maps $A$ to $B$\n",
    "- $n$: Number of pixels in images $A$ and $B$\n",
    "- $d$: Dimensionality of images $A$ and $B$\n",
    "- $X$ ($n \\times d$): Set of pixel locations in $d$-dimensional space, where $X_i$ be the $i^{th}$ pixel location\n",
    "- $a$, $b$ ($n \\times 1$): Pixel intensities for the images $A$ and $B$ (e.g. $a_i$ is the intensity at location $X_i$ in image $A$)\n",
    "- $P$ ($n \\times n$): Optimal transport matrix for $a$ and $b$\n",
    "- $\\hat{P}_{ij}(\\theta)$ ($n \\times n$): Parametric form of transportation plan corresponding to $T_{\\theta}$\n",
    "\n",
    "#### Parametric form for transportation plan \n",
    "\n",
    "We assume the following parametric form for the transportation plan corresponding to $T_{\\theta}$:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\hat{P}_{ij}(\\theta) = a_i \\cdot \\exp \\big( \\frac{-||T_{\\theta}(X_i) - X_j||_2^2}{2\\sigma^2} \\big)\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "This form assumes that the transportation plan for a particular $T_{\\theta}$ should transport all the mass $a_i$ from a particular pixel in $A$ to a Gaussian point spread function centered at $T_{\\theta}(X_i)$, with a spread parameter $\\sigma$. It's important to note that, for all values of $\\theta$, $\\hat{P}(\\theta)$ represents a valid joint probability distribution over $(i, j)$, and its first marginal distribution is $a$.\n",
    "\n",
    "#### Loss function\n",
    "\n",
    "To estimate $\\theta$, we first compute the optimal transportation plan $P$ between the distributions $a$ and $b$, using a cost matrix consisting of squared euclidean distances between the pixel locations in $X$. Then, we minimize the KL divergence between $P$ and $\\hat{P}(\\theta)$:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\theta^* = \\underset{\\theta}{\\mathrm{argmin\\ }} D_{KL}(P || \\hat{P}(\\theta))\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "This KL divergence can be computed using the parametric form we chose for $\\hat{P}(\\theta)$:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "D_{KL}(P || \\hat{P}(\\theta)) \n",
    "    &= \\sum_{i, j} P_{ij} \\log \\frac{P_{ij}}{\\hat{P}_{ij}(\\theta)} \\\\\n",
    "    &= \\sum_{i, j} P_{ij} \\log P_{ij} - \\sum_{i, j} P_{ij} \\log \\hat{P}_{ij}(\\theta) \\\\\n",
    "    &= \\sum_{i, j} P_{ij} \\log P_{ij} - \\sum_{i, j} P_{ij} \\log \\big[ a_i \\cdot \\exp \\big( \\frac{-||T_{\\theta}(X_i) - X_j||_2^2}{2\\sigma^2} \\big) \\big] \\\\\n",
    "    &= \\sum_{i, j} P_{ij} \\log P_{ij} - \\sum_{i, j} P_{ij} \\log a_i  + \\sum_{i, j} P_{ij} \\frac{||T_{\\theta}(X_i) - X_j||_2^2}{2\\sigma^2} \\\\\n",
    "\\end{align*} \n",
    "$\n",
    "\n",
    "Minimizing this with respect to $\\theta$, we can ignore the first two terms:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\theta^*\n",
    "    &= \\underset{\\theta}{\\mathrm{argmin\\ }} D_{KL}(P || \\hat{P}(\\theta)) \\\\\n",
    "    &= \\underset{\\theta}{\\mathrm{argmin\\ }} \\sum_{i, j} P_{ij} \\log P_{ij} - \\sum_{i, j} P_{ij} \\log a_i  + \\sum_{i, j} P_{ij} \\frac{||T_{\\theta}(X_i) - X_j||_2^2}{2\\sigma^2} \\\\\n",
    "    &= \\underset{\\theta}{\\mathrm{argmin\\ }} \\sum_{i, j} P_{ij} \\frac{||T_{\\theta}(X_i) - X_j||_2^2}{2\\sigma^2} \\\\\n",
    "    &= \\underset{\\theta}{\\mathrm{argmin\\ }} \\sum_{i, j} P_{ij} \\cdot ||T_{\\theta}(X_i) - X_j||_2^2 \\\\\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "This minimization problem is equivalent to performing a weighted, least-squares regression where the data set consists of all pairs of pixel locations $(X_i, X_j)$, each weighted by their corresponding value $P_{ij}$ in the optimal transport plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic example\n",
    "\n",
    "### Parametric form for $T$ and loss function\n",
    "\n",
    "For this example, we will make $T$ an affine transform, where $T_{\\theta}(x) = \\alpha + \\beta x$, with $\\theta = \\{\\alpha, \\beta\\}$. The loss function then becomes:\n",
    "\n",
    "$\n",
    "\\begin{equation*}\n",
    "\\alpha^*, \\beta^* = \\underset{\\alpha, \\beta}{\\mathrm{argmin\\ }} \\sum_{i, j} P_{ij} \\cdot ||\\beta X_i + \\alpha - X_j||_2^2\n",
    "\\end{equation*}\n",
    "$\n",
    "\n",
    "As noted above, this is equivalent to a weighted, least-squares regression problem, in this case a linear regression, with a dataset containing all pairs of pixel locations. For high-resolution images, this set of points might be prohibitively large, but we can take advantange of the sparsity of $P$ to approximate this sum by only summing over pixel pairs $(i,j)$ where the weight $P_{ij}$ is greater than some chosen threshold.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "In the code below, we create two images related by an affine transformation, and try to use our OT-registration method to recover this transformation and reconstruct image $B$ from image $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ot\n",
    "from scipy.ndimage import affine_transform\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from utils import plot_maxproj, pixel_dist_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed \n",
    "np.random.seed(1993)\n",
    "\n",
    "# Image size\n",
    "img_shape = (50, 25, 5)\n",
    "n_pixels = img_shape[0] * img_shape[1] * img_shape[2]\n",
    "\n",
    "# Grid for evaluating densities on\n",
    "xg, yg, zg = np.mgrid[0:img_shape[0], 0:img_shape[1], 0:img_shape[2]]\n",
    "grid = np.stack((xg, yg, zg), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create image $A$: Sum of three truncated Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Cells' are truncated Gaussians\n",
    "th = 1e-4\n",
    "cov = 3 * np.eye(3)\n",
    "mu_1 = np.array([20, 10, 3])\n",
    "mu_2 = np.array([10, 15, 3])\n",
    "mu_3 = np.array([10, 5, 3])\n",
    "cell_1 = multivariate_normal.pdf(grid, mu_1, cov).reshape(img_shape)\n",
    "cell_2 = multivariate_normal.pdf(grid, mu_2, cov).reshape(img_shape)\n",
    "cell_3 = multivariate_normal.pdf(grid, mu_3, cov).reshape(img_shape)\n",
    "cell_1[cell_1 < th] = 0 \n",
    "cell_2[cell_2 < th] = 0 \n",
    "cell_3[cell_3 < th] = 0 \n",
    "\n",
    "# First image contains two 'cells'\n",
    "A = cell_1  + cell_2 + cell_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose ground-truth $\\alpha$ and $\\beta$ and use them to create image $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transformation to apply to source image\n",
    "#theta = np.pi / 16\n",
    "#beta = np.array([\n",
    "#    [np.cos(theta), -np.sin(theta), 0], \n",
    "#    [np.sin(theta),  np.cos(theta), 0],\n",
    "#    [0,              0,             1]\n",
    "#])\n",
    "beta = np.eye(3, 3)\n",
    "alpha = np.array([12, 5, 0])\n",
    "#alpha = np.array([0, 0, 0])\n",
    "\n",
    "# Create B by applying T to A (requires inverse of T)\n",
    "inv_beta = np.linalg.inv(beta)\n",
    "inv_alpha = -inv_beta @ alpha\n",
    "B = affine_transform(A, inv_beta, inv_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add floor value and noise, normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "floor_val = 1e-7\n",
    "noise_level = 0\n",
    "\n",
    "# Noise is absolute value of Gaussian\n",
    "noise_1 = np.abs(np.random.randn(*img_shape)) * noise_level\n",
    "noise_2 = np.abs(np.random.randn(*img_shape)) * noise_level\n",
    "\n",
    "# Add floor value and noise\n",
    "A = A + floor_val + noise_1\n",
    "B = B + floor_val + noise_2\n",
    "\n",
    "# Normalize images\n",
    "A = A / np.sum(A)\n",
    "B = B / np.sum(B)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plot_maxproj(A)\n",
    "plt.title('A')\n",
    "plt.axis('off');\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_maxproj(B)\n",
    "plt.title('B')\n",
    "plt.axis('off');\n",
    "\n",
    "print(f'image shape: {img_shape}')\n",
    "print(f'num. pixels: {n_pixels}')\n",
    "print('alpha:')\n",
    "print(alpha)\n",
    "print('beta:')\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute optimal transport plan between frames\n",
    "\n",
    "**Note:** Right now, we're using the balanced OT approach (`ot.sinkhorn()`) to compute the optimal transport plan between images. While this holds for the synthetic example (i.e. mass is conserved), it might not hold for true data. Need to figure out how to get unbalanced OT approach (`ot.unbalanced.sinkhorn_unbalanced()`) to work here, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropic regularization parameter\n",
    "reg = 1e-3\n",
    "\n",
    "# Normalized pixel distance matrix \n",
    "M_nn = pixel_dist_3d(*img_shape)\n",
    "M = M_nn / np.median(M_nn)\n",
    "\n",
    "# Compute transport plan\n",
    "P = ot.sinkhorn(A.flatten(), B.flatten(), M, reg, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimize cost function to estimate $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha (est):\n",
      "[11.87009181  7.36828437  0.07776278]\n",
      "alpha (true):\n",
      "[12  5  0]\n",
      "beta (est):\n",
      "[[ 9.73388326e-01  4.93501370e-02 -7.10781743e-04]\n",
      " [-3.01815149e-02  7.98399993e-01 -4.70360693e-03]\n",
      " [ 5.17250258e-05 -1.48691057e-05  9.68740056e-01]]\n",
      "beta (true):\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Threshold to apply to P matrix (this speeds up computation)\n",
    "p_th = 1e-7\n",
    "\n",
    "# Pixel locations\n",
    "X = grid.reshape(-1, 3)\n",
    "\n",
    "# Get pairs of points with values above threshold, and corresponding weights from P matrix\n",
    "a_idx, b_idx = np.nonzero(P > p_th)\n",
    "pts_a = X[a_idx]\n",
    "pts_b = X[b_idx]\n",
    "weights = P[a_idx, b_idx]\n",
    "\n",
    "# Use sklearn.linear_model.LinearRegression to minimize cost function\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(pts_a, pts_b, sample_weight=weights)\n",
    "\n",
    "# Estimates of transform parameters\n",
    "alpha_est = model.intercept_\n",
    "beta_est = model.coef_\n",
    "\n",
    "print('alpha (est):')\n",
    "print(alpha_est)\n",
    "print('alpha (true):')\n",
    "print(alpha)\n",
    "\n",
    "print('beta (est):')\n",
    "print(beta_est)\n",
    "print('beta (true):')\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use estimated transform $T_{\\alpha^*, \\beta^*}$ to reconstruct $B$ from $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reconstruct A from B\n",
    "inv_beta_est = np.linalg.inv(beta_est)\n",
    "inv_alpha_est = -inv_beta_est @ alpha_est\n",
    "B_recon = affine_transform(A, inv_beta_est, inv_alpha_est)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(131)\n",
    "plot_maxproj(A)\n",
    "plt.title('A')\n",
    "        \n",
    "plt.subplot(132)\n",
    "plot_maxproj(B)\n",
    "plt.title('B')\n",
    "        \n",
    "plt.subplot(133)\n",
    "plot_maxproj(B_recon)\n",
    "plt.title('B (reconstruction)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
